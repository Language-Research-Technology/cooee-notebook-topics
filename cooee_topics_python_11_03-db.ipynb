{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ffb99-3330-48d1-a52c-5c6ed5fe45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rocrate-tabular\n",
    "\n",
    "!pip install git+https://github.com/Sydney-Informatics-Hub/rocrate-tabular.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b5714-17a7-483b-9778-11bec6206b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os                                                  # Functions for interacting with the operating system.\n",
    "import zipfile                                             # Tools to create, read, write, append and list a ZIP file.\n",
    "import requests                                            # Send HTTP requests.\n",
    "from io import BytesIO                                     # Perform file operations on byte data.\n",
    "from rocrate_tabular.tabulator import ROCrateTabulator     # Python library to turn an RO-Crate into tabular formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb88ca-72d6-4595-a8b6-8c317f4b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the names of the database, folder and configuration file to be created, or leave as the defaults.\n",
    "\n",
    "database = 'cooee.db'     # Edit the section in quotes to rename the database.\n",
    "folder = 'cooee'          # Edit the section in quotes to rename the folder that is created for the database.\n",
    "config = 'config.json'    # Edit the section in quotes to rename the configuration file to generate the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbc97e-3bd0-46d3-b830-2ee7654d7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the COOEE collection ZIP from the LDaCA data portal and extract it to a folder in the current working directory.\n",
    "\n",
    "zip_url = \"https://data.ldaca.edu.au/api/object/arcp%3A%2F%2Fname%2Chdl10.26180~23961609.zip\"\n",
    "cwd = os.getcwd()\n",
    "extract_to = os.path.join(cwd, folder)\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "response = requests.get(zip_url, stream=True)\n",
    "response.raise_for_status()\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extractall(extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87b75b-4c90-4fb3-bd4c-a6a126d36de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RO-Crate to a database. Arguments specified are the RO-Crate directory and the output name of the database.\n",
    "\n",
    "tb = ROCrateTabulator()\n",
    "tb.crate_to_db(folder, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d2310-bd1f-4eac-ada5-dc1164df4f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create or update the config file, specifying that `indexableText` is the entity containing text data for COOEE.\n",
    "\n",
    "if os.path.exists(config):\n",
    "    tb.load_config(config)\n",
    "    print(\"load\")\n",
    "else:\n",
    "    tb.infer_config()\n",
    "    print(\"infer\")\n",
    "\n",
    "for table in tb.cf[\"tables\"]:\n",
    "    print(f\"Building entity table for {table}\")\n",
    "    tb.entity_table(table, 'indexableText')\n",
    "\n",
    "tb.write_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b0580-76f1-4d4f-bd93-81b604085822",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Once the `config.json` file is generated, right-click it in the File Browser and select 'Open With' > 'Editor'.\n",
    "\n",
    "Replace the section `\"tables\": {},` with the following:\n",
    "```\n",
    "    \"tables\": {\n",
    "        \"RepositoryObject\": {\n",
    "            \"all_props\": [],\n",
    "            \"ignore_props\": [],\n",
    "            \"expand_props\": []\n",
    "        }\n",
    "    },\n",
    "```\n",
    "<br>\n",
    "\n",
    "This indicates that we want to use the `RepositoryObject` class to generate the table in the database.\n",
    "\n",
    "Then remove the following section from `potential_tables`:\n",
    "```\n",
    "        \"RepositoryObject\": {\n",
    "            \"all_props\": [],\n",
    "            \"ignore_props\": [],\n",
    "            \"expand_props\": []\n",
    "        },\n",
    "```\n",
    "<br>\n",
    "\n",
    "Save `config.json` and close it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a252cf-0902-49fc-93da-cedce58d01a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now that the config table has been updated, re-generate the database output.\n",
    "\n",
    "tb.crate_to_db(folder, database)\n",
    "\n",
    "if os.path.exists(config):\n",
    "    tb.load_config(config)\n",
    "    print(\"load\")\n",
    "else:\n",
    "    tb.infer_config()\n",
    "    print(\"infer\")\n",
    "\n",
    "for table in tb.cf[\"tables\"]:\n",
    "    print(f\"Building entity table for {table}\")\n",
    "    tb.entity_table(table, 'indexableText')\n",
    "\n",
    "tb.write_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc6721-9993-4194-98e3-fc1b3ea04073",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Open `config.json` again. The `all_props` section should be populated. If you need to do a subquery on a target ID to make expanded properties such as `author_name` and `author_id`, copy the required properties to the `expand_props` section. For example:\n",
    "\n",
    "```\n",
    "            \"expand_props\": [\n",
    "                \"author\",\n",
    "                \"register\",\n",
    "                \"recipient\"\n",
    "            ]\n",
    "```\n",
    "<br>\n",
    "\n",
    "This indicates that we want the `author`, `register` and `recipient` properties to be expanded in the database.\n",
    "\n",
    "Save `config.json` and close it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf7230-279f-4dce-b21b-f34302c7c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-generate the database output to include the expanded properties in the database.\n",
    "\n",
    "tb.crate_to_db(folder, database)\n",
    "\n",
    "if os.path.exists(config):\n",
    "    tb.load_config(config)\n",
    "    print(\"load\")\n",
    "else:\n",
    "    tb.infer_config()\n",
    "    print(\"infer\")\n",
    "\n",
    "for table in tb.cf[\"tables\"]:\n",
    "    print(f\"Building entity table for {table}\")\n",
    "    tb.entity_table(table, 'indexableText')\n",
    "\n",
    "tb.write_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb458ea-d4e4-40b7-a131-73b1f62250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tb.export_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0e067-5432-4756-a7ad-64372e8d6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cooee.db version\n",
    "\n",
    "import sqlite3\n",
    "import pandas\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "# Write an SQL query to select data\n",
    "query = \"SELECT * FROM RepositoryObject\"  # Replace with your table name if not using RepositoryObject\n",
    "\n",
    "# Read data into a Pandas DataFrame\n",
    "df = pandas.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "#Remove the first row of the DataFrame\n",
    "cooee = df.iloc[1:]\n",
    "\n",
    "# Remove rows where 'indexableText' column has NaN values\n",
    "#cooee = df.dropna(subset=['indexableText'])\n",
    "\n",
    "# Display the DataFrame\n",
    "cooee.info()\n",
    "cooee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d4e0d-6ef0-465a-aa10-4795dd95732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame where 'indexableText' is NaN\n",
    "filtered_df = cooee[cooee['indexableText'].isna()]\n",
    "\n",
    "# Select only 'entity_id' and 'indexableText' columns\n",
    "result = filtered_df[['entity_id', 'name', 'indexableText']]\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9f5f3-b8e4-45e9-b1a9-319b0149aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7414c-d1fd-40ef-bfa8-423ff2be0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split cooee data frame into 16 subsets\n",
    "\n",
    "registers = {\"full\": [\"Government English\", \"Private Written\", \"Public Written\", \"Speech Based\"], \"short\": [\"ge\", \"prw\", \"puw\", \"sb\"]}\n",
    "registers = pandas.DataFrame(registers)\n",
    "print(registers)\n",
    "\n",
    "periods = {\"period\": [1,2,3,4], \"start\": [1788, 1826, 1851, 1876], \"end\": [1825, 1850, 1875, 1900]}\n",
    "time_periods = pandas.DataFrame(periods)\n",
    "print(time_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07b20f-f49c-49d4-ad11-cfcb54d4b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cooee.db version\n",
    "\n",
    "# make a single document for each subset from indexableText\n",
    "\n",
    "## make dataframe with sub-corpora\n",
    "sub_titles = []\n",
    "documents = []\n",
    "\n",
    "for i in range(0, 4):\n",
    "    for j in range(0, 4):\n",
    "        sub_title = registers.iloc[i, 1] + \"_period\" + str(time_periods.iloc[j, 0])\n",
    "        sub_titles.append(sub_title)\n",
    "        \n",
    "        # Ensure the values for time_periods are numeric\n",
    "        start_period = pandas.to_numeric(time_periods.iloc[j, 1], errors='coerce')  # Convert to numeric\n",
    "        end_period = pandas.to_numeric(time_periods.iloc[j, 2], errors='coerce')    # Convert to numeric\n",
    "        \n",
    "        # Convert column 19 of cooee DataFrame to numeric values (errors='coerce' will turn non-numeric into NaN)\n",
    "        cooee.iloc[:, 19] = pandas.to_numeric(cooee.iloc[:, 19], errors='coerce')\n",
    "        \n",
    "        # Filter cooee DataFrame based on conditions\n",
    "        temp = cooee.loc[\n",
    "            (cooee[\"register\"] == registers.iloc[i, 0]) & \n",
    "            (cooee.iloc[:, 19] >= start_period) &  # Ensure comparison with numeric values\n",
    "            (cooee.iloc[:, 19] <= end_period)    # Ensure comparison with numeric values\n",
    "        ]\n",
    "        \n",
    "        texts = \"\"\n",
    "\n",
    "        for row in temp:\n",
    "            text = temp[\"indexableText\"].to_string()\n",
    "            texts = texts + text\n",
    "        documents.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05196fd0-e0c1-47eb-a6f3-d269d2dc319a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8deb5bd-85f2-4800-b0b5-893edf8bcb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing and lemmatizing\n",
    " \n",
    "clean_documents = []\n",
    "\n",
    "for i in range(0,len(documents)):\n",
    "    text = str(documents[i])\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    clean_documents.append(cleaned_tokens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafefcbe-9a63-4864-8a09-a46cece23739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing and lemmatizing\n",
    "\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "clean_documents = []\n",
    "\n",
    "for i in range(0,len(documents)):\n",
    "    text = str(documents[i])\n",
    "    tokens = word_tokenize(text)\n",
    "    # Function to get the POS tag for lemmatization\n",
    "def get_pos(word):\n",
    "    tag = pos_tag([word])[0][1]\n",
    "    if tag.startswith('VB'):\n",
    "        return 'v'  # Verb\n",
    "    elif tag.startswith('NN'):\n",
    "        return 'n'  # Noun\n",
    "    elif tag.startswith('JJ'):\n",
    "        return 'a'  # Adjective\n",
    "    else:\n",
    "        return 'n'  # Default to noun if unknown\n",
    "\n",
    "# Lemmatize and remove stopwords\n",
    "cleaned_tokens = [\n",
    "    lemmatizer.lemmatize(word.lower(), get_pos(word)) \n",
    "    for word in tokens \n",
    "    if word.isalpha() and lemmatizer.lemmatize(word.lower(), get_pos(word)) not in stop_words\n",
    "]\n",
    "\n",
    "clean_documents.append(cleaned_tokens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5916763-f495-4d4a-98e8-585a8ddbdce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6fec8-1a95-477d-9f15-c6d5a402a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018f261-e26b-43c0-a35f-61c025fa0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary and corpus\n",
    "dictionary = Dictionary(clean_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in clean_documents]\n",
    "\n",
    "# Running LDA TO DO: check parameters especailly passes\n",
    "lda_model = LdaModel(corpus, num_topics=20, id2word=dictionary, passes=100, random_state=100)\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017e1df-31f1-4cc0-a312-5eddc75b6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: revise this to give nice screen display like Sam's\n",
    "\n",
    "top_words_per_topic = []\n",
    "for t in range(lda_model.num_topics):\n",
    "    top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
    "\n",
    "# top_words_per_topic\n",
    "top_words = pandas.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P'])\n",
    "top_words\n",
    "# top_words_transpose = top_words.transpose()\n",
    "# top_words_transpose\n",
    "\n",
    "# pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P']).to_csv(\"top_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0152fb8-c75f-4bfd-a969-e1d8097038ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0319526-c342-4370-a9d6-29c0e8912e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular display\n",
    "\n",
    "topics_table = pandas.DataFrame()\n",
    "for i in range(0,20):\n",
    "    col_name = \"Topic\" + str(i+1)\n",
    "    temp = top_words.loc[(top_words[\"Topic\"] == i)]\n",
    "    temp_words = temp[\"Word\"].to_list()\n",
    "    topics_table[col_name] = temp_words\n",
    "topics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860cd68-9fc3-46c2-a93f-203805c73dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get weightings for each document\n",
    "\n",
    "doc_weights = []\n",
    "\n",
    "for doc in clean_documents:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    t = lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "    doc_weights.append(t)\n",
    "\n",
    "doc_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26c4af-6116-4fe2-a0c9-93ba037e0b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop document numbers from weights list\n",
    "\n",
    "weights = []\n",
    "\n",
    "for doc_row in doc_weights:\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for item in doc_row:\n",
    "        weight = item[1]\n",
    "        out.append(weight)\n",
    "    weights.append(out)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a2eb1-a28f-45ff-8dc1-a477bab19bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = []\n",
    "\n",
    "for i in range(0,20):\n",
    "    topic_name = \"Topic\"+ str(i+1) + \" \" + topics_table.iloc[1, i] + \" \" + topics_table.iloc[2, i]  +\" \" + topics_table.iloc[3, i]\n",
    "    topic_names.append(topic_name)\n",
    "\n",
    "topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60aa98-54ba-4bed-b520-431f2489aed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# massage data to be input for visualisation\n",
    "\n",
    "topic_df = (pandas.DataFrame(weights, columns= topic_names))\n",
    "\n",
    "topics_transpose = topic_df.transpose()\n",
    "topics_transpose.columns = sub_titles       \n",
    "# Output the DataFrame\n",
    "print(topics_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96bd14-34d5-44f7-b0e8-2e6e085909d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed\n",
    "\n",
    "pip install pheatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80c75f-b786-4c5f-94ad-ccc891cc0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed\n",
    "\n",
    "from pheatmap import pheatmap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053907af-393c-4450-8000-6d6e6dc013c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use this one! \n",
    "\n",
    "fig = pheatmap(topics_transpose,  cmap = \"Greens\", colnames_style={\"rotation\": 90})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4297fb-0d58-43e9-8812-112326dbe06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097d53-54be-4320-82b9-7ed3a7eddda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 6))  # Adjust the width and height\n",
    "sns.heatmap(topics_transpose, \n",
    "            cmap='Blues',  # 'Reds' colormap corresponds to the red color scheme\n",
    "            cbar_kws={'label': 'Topic Weight'},  # Color bar label\n",
    "            linewidths=0,  # No lines between cells\n",
    "            xticklabels=True,  # Show column labels\n",
    "            yticklabels=True,  # Show row labels\n",
    "            square=False,  # To avoid forcing the aspect ratio to be square\n",
    "            cbar=True)  # Display color bar\n",
    "\n",
    "# Rotate column labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Save the heatmap to a PDF file\n",
    "# plt.savefig(\"results/convo_topic_heatmap.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
